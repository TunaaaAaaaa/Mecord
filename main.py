import streamlit as st
import requests
import json
import os
from dotenv import load_dotenv
from knowledge_base import KnowledgeBase

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·å–APIå¯†é’¥å’ŒURL
API_KEY = os.getenv("API_KEY")

API_URL = os.getenv("API_URL")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="æƒ…ç»ªåˆ†æåŠ©æ‰‹", page_icon="ğŸ˜Š")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# åˆå§‹åŒ–çŸ¥è¯†åº“
if "knowledge_base" not in st.session_state:
    st.session_state.knowledge_base = KnowledgeBase(API_KEY)
    st.session_state.knowledge_base.initialize_vector_store()

# åˆ†ææƒ…ç»ªå‡½æ•°
def analyze_emotion(text):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    
    payload = {
        "model": "deepseek-ai/DeepSeek-V3",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæƒ…ç»ªåˆ†æä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·è¾“å…¥çš„æƒ…ç»ªï¼Œå¹¶ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªæœ€åŒ¹é…çš„æƒ…ç»ªç±»åˆ«ï¼šå¼€å¿ƒã€æ‚²ä¼¤ã€æ„¤æ€’ã€ç„¦è™‘ã€å›°æƒ‘ã€ä¸­æ€§ã€‚åªéœ€å›å¤æƒ…ç»ªç±»åˆ«ï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ã€‚"}, 
            {"role": "user", "content": text}
        ],
        "temperature": 0.3
    }
    
    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        result = response.json()
        emotion = result["choices"][0]["message"]["content"].strip()
        return emotion
    except Exception as e:
        st.error(f"åˆ†ææƒ…ç»ªæ—¶å‡ºé”™: {str(e)}")
        return "ä¸­æ€§"  # å‡ºé”™æ—¶è¿”å›é»˜è®¤æƒ…ç»ª

# ç”Ÿæˆå›åº”å‡½æ•°
def generate_response(text, emotion):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    
    # ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹
    relevant_docs = st.session_state.knowledge_base.search_knowledge(text)
    knowledge_context = "\n".join(relevant_docs) if relevant_docs else ""
    
    prompt = f"ç”¨æˆ·è¯´: '{text}'\nç”¨æˆ·çš„æƒ…ç»ªä¼¼ä¹æ˜¯: {emotion}\n"
    if knowledge_context:
        prompt += f"æ ¹æ®çŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯ï¼š\n{knowledge_context}\n"
    prompt += f"è¯·å‘ŠçŸ¥ç”¨æˆ·ä»–çš„æƒ…ç»ªç±»å‹ä¸º{emotion}ï¼Œå¹¶ç»“åˆçŸ¥è¯†åº“ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰ç»™å‡ºé€‚åˆè¿™ç§æƒ…ç»ªçš„å›åº”ï¼Œæä¾›å®‰æ…°ã€å»ºè®®æˆ–ç§¯æçš„åé¦ˆã€‚"
    
    payload = {
        "model": "deepseek-ai/DeepSeek-V3",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå–„è§£äººæ„çš„å¿ƒç†å’¨è¯¢å¸ˆï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·çš„æƒ…ç»ªçŠ¶æ€å’Œç›¸å…³çŸ¥è¯†æä¾›æ°å½“çš„å›åº”å’Œå»ºè®®ã€‚"}, 
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }
    
    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        result = response.json()
        return result["choices"][0]["message"]["content"]
    except Exception as e:
        st.error(f"ç”Ÿæˆå›åº”æ—¶å‡ºé”™: {str(e)}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•æä¾›å›åº”ã€‚è¯·ç¨åå†è¯•ã€‚"  # å‡ºé”™æ—¶è¿”å›é»˜è®¤å›åº”

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("æƒ…ç»ªåˆ†æåŠ©æ‰‹")
    st.markdown("è¿™æ˜¯ä¸€ä¸ªèƒ½å¤Ÿåˆ†æä½ æƒ…ç»ªå¹¶ç»™å‡ºå›åº”çš„AIåŠ©æ‰‹ã€‚")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ çŸ¥è¯†åº“æ–‡æ¡£", type=["txt", "md", "pdf"])
    if uploaded_file:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        file_path = os.path.join("knowledge_docs", uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        # æ›´æ–°çŸ¥è¯†åº“
        if st.session_state.knowledge_base.add_document(file_path):
            st.success(f"æ–‡ä»¶ {uploaded_file.name} å·²æ·»åŠ åˆ°çŸ¥è¯†åº“")
        else:
            st.error("æ·»åŠ æ–‡ä»¶å¤±è´¥")
    
    if st.button("æ¸…é™¤å¯¹è¯å†å²"):
        st.session_state.messages = []
        st.experimental_rerun()

# ä¸»ç•Œé¢
st.title("æƒ…ç»ªåˆ†æåŠ©æ‰‹ ğŸ§ ğŸ’­")

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "emotion" in message:
            st.caption(f"æ£€æµ‹åˆ°çš„æƒ…ç»ª: {message['emotion']}")

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥ä½ æƒ³è¡¨è¾¾çš„å†…å®¹..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # æ˜¾ç¤ºåŠ©æ‰‹æ€è€ƒä¸­
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("æ€è€ƒä¸­...")
        
        # åˆ†ææƒ…ç»ª
        emotion = analyze_emotion(prompt)
        
        # ç”Ÿæˆå›åº”
        response = generate_response(prompt, emotion)
        
        # æ›´æ–°æ¶ˆæ¯
        message_placeholder.markdown(response)
    
    # æ·»åŠ åŠ©æ‰‹å›åº”åˆ°å†å²
    st.session_state.messages.append({"role": "assistant", "content": response, "emotion": emotion})